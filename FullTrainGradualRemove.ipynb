{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Full Train Gradual Remove\n",
        "### MNIST Forgetting"
      ],
      "metadata": {
        "id": "HYHV1bUs2QhD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDCZ8rN-2QJF"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 5000\n",
        "num_classes = 10\n",
        "epochs = 1\n",
        "epochs_part = 1\n",
        "repeat = 2\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "y_temp = []\n",
        "x_temp = []\n",
        "class_len = []\n",
        "print(y_train.shape)\n",
        "print(x_train.shape)\n",
        "\n",
        "for i in range (0, num_classes):\n",
        "\tk = 0\n",
        "\tfor j in range (0, len(y_train)):\n",
        "\t\tif y_train[j] == i:\n",
        "\t\t\ty_temp.append(y_train[j])\n",
        "\t\t\tx_temp.append(x_train[j,:,:])\t\n",
        "\t\t\tk = k + 1\n",
        "\tclass_len.append(k)\n",
        "\t# print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf1_-RlD2cUw",
        "outputId": "4a9dee52-bc9d-4c8f-dbb3-11a6e2ebac9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "(60000,)\n",
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_old = x_train\n",
        "y_train_old = y_train\n",
        "y_train = np.array(y_temp)\n",
        "x_train = np.array(x_temp)\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "class_len = np.array(class_len)\n",
        "print(class_len)\n",
        "\n",
        "y_temp = []\n",
        "x_temp = []\n",
        "test_class_len = []\n",
        "print(y_test.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "for i in range (0,num_classes):\n",
        "\tk = 0\n",
        "\tfor j in range (0,len(y_test)):\n",
        "\t\tif y_test[j] == i:\n",
        "\t\t\ty_temp.append(y_test[j])\n",
        "\t\t\tx_temp.append(x_test[j,:,:])\t\n",
        "\t\t\tk = k+1\n",
        "\ttest_class_len.append(k)\n",
        "\t# print(k)\n",
        "\n",
        "x_test_old = x_test\n",
        "y_test_old = y_test\n",
        "x_test = np.array(x_temp)\n",
        "y_test = np.array(y_temp)\n",
        "print(x_test.shape)\n",
        "test_class_len = np.array(test_class_len)\n",
        "print(test_class_len)\n",
        "# np.savez(mnist,x_train=x_train,y_train=y_train,x_test=x_test,y_test=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRZI8C332jNb",
        "outputId": "ca05f259-2887-4db5-d05e-7cdf9c4b57ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "[5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n",
            "(10000,)\n",
            "(10000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "[ 980 1135 1032 1010  982  892  958 1028  974 1009]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_train_old = x_train_old.reshape(x_train_old.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_train_old = x_train_old.reshape(x_train_old.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train_old = x_train_old.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_train_old /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "ytrain_old = y_train_old\n",
        "y_train_old = keras.utils.to_categorical(y_train_old, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-4-ICiT2uL2",
        "outputId": "0092641b-da6b-46c2-8628-7d7d1059ed5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3gNFVL272xuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_len = len(y_train_old)\n",
        "train_acc_full = []\n",
        "train_loss_full = []\n",
        "val_acc_full = []\n",
        "val_loss_full = []\n",
        "l = 0\n",
        "test_acc_full = np.zeros((num_classes, int(epochs*train_len/batch_size)))\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "        k = 0\n",
        "        for i in range (0, int(train_len/batch_size)):\n",
        "                hist = model.fit(x_train_old[k:k+batch_size], y_train_old[k:k+batch_size],batch_size=batch_size,epochs=1,verbose=1,validation_data=(x_test, y_test), shuffle=True)\n",
        "                train_acc_full.append(hist.history['accuracy'])\n",
        "                train_loss_full.append(hist.history['loss'])\n",
        "                val_acc_full.append(hist.history['val_accuracy'])\n",
        "                val_loss_full.append(hist.history['val_loss'])\n",
        "                # Classwise\n",
        "                m = 0\n",
        "                for j in range (0, num_classes):\n",
        "                        score = model.evaluate(x_test[m:m+test_class_len[j]], y_test[m:m+test_class_len[j]], verbose=0)\n",
        "                        #print(score[1])\n",
        "                        test_acc_full[j,l] = score[1]\n",
        "                        m = m + test_class_len[j]\n",
        "                l = l + 1\t\n",
        "                k = k + batch_size\n",
        "\n",
        "train_acc_full = np.array(train_acc_full)\n",
        "train_loss_full = np.array(train_loss_full)\n",
        "val_acc_full = np.array(val_acc_full)\n",
        "val_loss_full = np.array(val_loss_full)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEfCGlvC22Ui",
        "outputId": "8ccbdf18-4799-46e1-f4bf-78d03e2e704c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 28s 28s/step - loss: 2.3016 - accuracy: 0.0924 - val_loss: 2.2974 - val_accuracy: 0.0873\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.3007 - accuracy: 0.1016 - val_loss: 2.2972 - val_accuracy: 0.0877\n",
            "1/1 [==============================] - 20s 20s/step - loss: 2.2980 - accuracy: 0.0964 - val_loss: 2.2971 - val_accuracy: 0.0880\n",
            "1/1 [==============================] - 24s 24s/step - loss: 2.2992 - accuracy: 0.1050 - val_loss: 2.2970 - val_accuracy: 0.0881\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.3009 - accuracy: 0.0946 - val_loss: 2.2969 - val_accuracy: 0.0884\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.2998 - accuracy: 0.1022 - val_loss: 2.2968 - val_accuracy: 0.0884\n",
            "1/1 [==============================] - 24s 24s/step - loss: 2.2985 - accuracy: 0.1002 - val_loss: 2.2967 - val_accuracy: 0.0885\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.2983 - accuracy: 0.1018 - val_loss: 2.2965 - val_accuracy: 0.0887\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.3002 - accuracy: 0.0946 - val_loss: 2.2964 - val_accuracy: 0.0891\n",
            "1/1 [==============================] - 34s 34s/step - loss: 2.2972 - accuracy: 0.1102 - val_loss: 2.2963 - val_accuracy: 0.0894\n",
            "1/1 [==============================] - 26s 26s/step - loss: 2.2988 - accuracy: 0.0956 - val_loss: 2.2962 - val_accuracy: 0.0896\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.2993 - accuracy: 0.1008 - val_loss: 2.2961 - val_accuracy: 0.0899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now Removing Begins\n",
        "\n",
        "train_acc_part=[]\n",
        "train_loss_part=[]\n",
        "val_acc_part=[]\n",
        "val_loss_part=[]\n",
        "l=0\n",
        "test_acc_part=np.zeros((num_classes,epochs_part*num_classes*repeat*np.int(np.floor((60000-6000)/batch_size)+1)))\n",
        "\n",
        "for epoch in range(0,epochs_part):\n",
        "        for num in range (0,num_classes):\n",
        "                y_temp=[]\n",
        "                x_temp=[]\n",
        "                for j in range (0,len(ytrain_old)):\n",
        "                        if ytrain_old[j]!=num:\n",
        "                                y_temp.append(ytrain_old[j])\n",
        "                                x_temp.append(x_train_old[j,:,:])\t\n",
        "                x_temp=np.array(x_temp)\n",
        "                y_temp=np.array(y_temp)\n",
        "                y_temp = keras.utils.to_categorical(y_temp, num_classes)\n",
        "                # Randomize\n",
        "                temp_len=len(y_temp)\n",
        "                print(x_temp.shape)\n",
        "                print(temp_len)\n",
        "                temp=np.arange(temp_len)\n",
        "                np.random.shuffle(temp)\n",
        "                for rep in range (0,repeat):\n",
        "                        print(np.int(np.floor(temp_len/batch_size)+1))\n",
        "                        k=0\n",
        "                        for i in range (0,np.int(np.floor(temp_len/batch_size)+1)):\n",
        "                                \n",
        "                                hist=model.fit(x_train[k:np.minimum(k+batch_size,temp_len)], y_train[k:np.minimum(k+batch_size,temp_len)],batch_size=np.minimum(batch_size,temp_len-k+1),epochs=1,verbose=1,validation_data=(x_test, y_test), shuffle=True)\n",
        "                                train_acc_part.append(hist.history['accuracy'])\n",
        "                                train_loss_part.append(hist.history['loss'])\n",
        "                                val_acc_part.append(hist.history['val_accuracy'])\n",
        "                                val_loss_part.append(hist.history['val_loss'])\n",
        "                                # Classwise\n",
        "                                m=0\n",
        "                                for j in range (0,num_classes):\n",
        "                                        score = model.evaluate(x_test[m:m+test_class_len[j]],y_test[m:m+test_class_len[j]], verbose=0)\n",
        "                                        #print(score[1])\n",
        "                                        test_acc_part[j,l]=score[1]\n",
        "                                        m=m+test_class_len[j]\n",
        "                                l=l+1\t\n",
        "                                k=k+batch_size\n",
        "                                \n",
        "                \n",
        "train_acc_part=np.array(train_acc_part)\n",
        "train_loss_part=np.array(train_loss_part)\n",
        "val_acc_part=np.array(val_acc_part)\n",
        "val_loss_part=np.array(val_loss_part)    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBV6Pnbb3IN6",
        "outputId": "3dd4b7af-4a0b-4f82-cbbf-136db172a7ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-e869f2ea76cb>:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  test_acc_part=np.zeros((num_classes,epochs_part*num_classes*repeat*np.int(np.floor((60000-6000)/batch_size)+1)))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(54077, 28, 28, 1)\n",
            "54077\n",
            "11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-e869f2ea76cb>:28: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  print(np.int(np.floor(temp_len/batch_size)+1))\n",
            "<ipython-input-11-e869f2ea76cb>:30: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  for i in range (0,np.int(np.floor(temp_len/batch_size)+1)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 36s 36s/step - loss: 2.2819 - accuracy: 0.0970 - val_loss: 2.2960 - val_accuracy: 0.0890\n",
            "1/1 [==============================] - 25s 25s/step - loss: 2.3248 - accuracy: 0.0408 - val_loss: 2.2959 - val_accuracy: 0.0886\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.3277 - accuracy: 0.0364 - val_loss: 2.2959 - val_accuracy: 0.0889\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.3136 - accuracy: 0.0592 - val_loss: 2.2958 - val_accuracy: 0.0895\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.3058 - accuracy: 0.0898 - val_loss: 2.2958 - val_accuracy: 0.0895\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.2429 - accuracy: 0.2910 - val_loss: 2.2958 - val_accuracy: 0.0902\n",
            "1/1 [==============================] - 24s 24s/step - loss: 2.3103 - accuracy: 0.0762 - val_loss: 2.2958 - val_accuracy: 0.0905\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.3067 - accuracy: 0.0858 - val_loss: 2.2957 - val_accuracy: 0.0907\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.3138 - accuracy: 0.0584 - val_loss: 2.2956 - val_accuracy: 0.0913\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.2955 - accuracy: 0.1096 - val_loss: 2.2955 - val_accuracy: 0.0914\n",
            "1/1 [==============================] - 21s 21s/step - loss: 2.2493 - accuracy: 0.2195 - val_loss: 2.2955 - val_accuracy: 0.0921\n",
            "11\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.2818 - accuracy: 0.0910 - val_loss: 2.2954 - val_accuracy: 0.0916\n",
            "1/1 [==============================] - 20s 20s/step - loss: 2.3232 - accuracy: 0.0416 - val_loss: 2.2953 - val_accuracy: 0.0913\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.3273 - accuracy: 0.0376 - val_loss: 2.2953 - val_accuracy: 0.0913\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.3158 - accuracy: 0.0506 - val_loss: 2.2952 - val_accuracy: 0.0916\n",
            "1/1 [==============================] - 22s 22s/step - loss: 2.3040 - accuracy: 0.0976 - val_loss: 2.2952 - val_accuracy: 0.0915\n",
            "1/1 [==============================] - 23s 23s/step - loss: 2.2436 - accuracy: 0.2938 - val_loss: 2.2952 - val_accuracy: 0.0920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(test_acc)\n",
        "np.savez('mnist_result_gradual'+str(epochs),test_acc_full=test_acc_full,train_acc_full=train_acc_full,train_loss_full=train_loss_full,val_acc_full=val_acc_full,val_loss_full=val_loss_full,test_acc_part=test_acc_part,train_acc_part=train_acc_part,train_loss_part=train_loss_part,val_acc_part=val_acc_part,val_loss_part=val_loss_part)\n",
        "plt.plot(val_acc_full)\n",
        "plt.ylabel('val_accuracy')\n",
        "plt.show()\n",
        "plt.plot(val_loss_full)\n",
        "plt.ylabel('val_loss')\n",
        "plt.show()\n",
        "plt.plot(train_acc_full)\n",
        "plt.ylabel('train_accuracy')\n",
        "plt.show()\n",
        "plt.plot(train_loss_full)\n",
        "plt.ylabel('train_loss')\n",
        "plt.show()\n",
        "plt.plot(val_acc_part)\n",
        "plt.ylabel('val_accuracy')\n",
        "plt.show()\n",
        "plt.plot(val_loss_part)\n",
        "plt.ylabel('val_loss')\n",
        "plt.show()\n",
        "plt.plot(train_acc_part)\n",
        "plt.ylabel('train_accuracy')\n",
        "plt.show()\n",
        "plt.plot(train_loss_part)\n",
        "plt.ylabel('train_loss')\n",
        "plt.show()\n",
        "'''\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "'''"
      ],
      "metadata": {
        "id": "r80iv7yq3Mly"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}